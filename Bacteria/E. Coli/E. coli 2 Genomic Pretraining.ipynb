{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. coli Promoter Classification with Genomic Pretraining\n",
    "\n",
    "This notebook builds on the previous one. Here, we show how using the [ULMFiT](https://arxiv.org/abs/1801.06146) technique of pretraining the classification model as a language model significantly improves performance. \n",
    "\n",
    "The \"language model\" here is a genomic prediction model. Given a sequence of input genomic tokens, the model outputs predictions of what token will be next. As described in the previous notebook, the genomic sequence will be represented by 5bp tokens with a stride of 2 between tokens.\n",
    "\n",
    "This allows us to train a model that learns representations of genomic tokens in a totally unsupervised way. The key difference that makes this technique different from previous methods that leverage pretraining for genomic classification (see [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6020378/), [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5954283/) and [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6189047/)) is we use a large, unlabeled genomic corpus. Previous implementations of unsupervised pre-training train on only the classification corpus or a synthetically generated corpus of sequences similar to the classification corpus. These methods limit the pre-training corpus by the user's ability to gather labeled data.\n",
    "\n",
    "Comparatively, the UMLFiT approach allows us to use any large corpus of genomic data, regardless of its relation to the classification data. This allows us to pretrain on more data and generate better models.\n",
    "\n",
    "Once the genomic language model is trained, we can transfer the encoding section of the model (embedding + LSTM layers) to the classification model. This allows us to port over more pretrained weights than just the vector embeddings for the k-mers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from Bio import Seq\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import FeatureLocation, CompoundLocation\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('F:/genome/e_coli/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'e_coli_lm_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language model data is just long strings of genomic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGTTTCACCGCCGGTAATGAAAAAGGCGAACTGGTGGTGCTTGGAC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGCTGGCTGAAGAATAAACATATCGACTTACGTGTCTGCGGTGTTG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCGTTGGTACTGCGCGGATATGGTGCGGGCAATGACGTTACAGCTG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CGCTCTGTGTGACAAGCCGGAAACCGCCCAGCGCGTTGCCGACTGG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sequence  is_train\n",
       "0  AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATT...         1\n",
       "1  GGTTTCACCGCCGGTAATGAAAAAGGCGAACTGGTGGTGCTTGGAC...         1\n",
       "2  AGCTGGCTGAAGAATAAACATATCGACTTACGTGTCTGCGGTGTTG...         1\n",
       "3  CCGTTGGTACTGCGCGGATATGGTGCGGGCAATGACGTTACAGCTG...         1\n",
       "4  CGCTCTGTGTGACAAGCCGGAAACCGCCCAGCGCGTTGCCGACTGG...         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of the data used for validation\n",
    "train_df, valid_df = split_data(df, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Numericalization\n",
    "\n",
    "The tokenization functions are the same as those described in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(GenomicTokenizer, n_cpus=1, pre_rules=[], post_rules=[], special_cases=['xxpad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "To create our dataloader, we use a slightly different variant of the classification dataloader. The `GenomicTextLMDataBunch` class sets up the data with a language model structure, where the correct y value for each token is the next sequential token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomicTextLMDataBunch(TextLMDataBunch):\n",
    "    @classmethod\n",
    "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
    "                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
    "                label_cols:IntsOrStrs=0, label_delim:str=None, chunksize:int=10000, max_vocab:int=60000,\n",
    "                min_freq:int=2, mark_fields:bool=False, bptt=70, collate_fn:Callable=data_collate, bs=64, **kwargs):\n",
    "        \"Create a `TextDataBunch` from DataFrames. `kwargs` are passed to the dataloader creation.\"\n",
    "        processor = _get_genomic_processor(tokenizer=tokenizer, vocab=vocab, chunksize=chunksize, max_vocab=max_vocab,\n",
    "                                   min_freq=min_freq, mark_fields=mark_fields)\n",
    "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
    "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
    "                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
    "        src = src.label_for_lm() \n",
    "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
    "        d1 = src.databunch(**kwargs)\n",
    "        \n",
    "        datasets = cls._init_ds(d1.train_ds, d1.valid_ds, d1.test_ds)            \n",
    "        val_bs = bs\n",
    "        datasets = [LanguageModelPreLoader(ds, shuffle=(i==0), bs=(bs if i==0 else val_bs), bptt=bptt, backwards=False) \n",
    "                    for i,ds in enumerate(datasets)]            \n",
    "        dls = [DataLoader(d, b, shuffle=False) for d,b in zip(datasets, (bs,val_bs,val_bs,val_bs)) if d is not None]\n",
    "        \n",
    "        return cls(*dls, path=path, collate_fn=collate_fn, no_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GenomicTextLMDataBunch.from_df(path, train_df, valid_df, bs=428, tokenizer=tok, text_cols=0, label_cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model vocabulary - 1025 tokens. 1024 5-mer nucleotide combinations plus one padding token\n",
    "len(data.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text AGCTT CTTTT TTTCA TCATT ATTCT TCTGA TGACT ACTGC TGCAA CAACG ACGGG GGGCA GCAAT AATAT TATGT TGTCT TCTCT TCTGT TGTGT TGTGG TGGAT GATTA TTAAA AAAAA AAAAA AAAGA AGAGT AGTGT TGTCT TCTGA TGATA ATAGC AGCAG CAGCT GCTTC TTCTG CTGAA GAACT ACTGG TGGTT GTTAC TACCT CCTGC TGCCG CCGTG GTGAG GAGTA GTAAA AAATT ATTAA TAAAA AAATT ATTTT TTTAT TATTG TTGAC GACTT CTTAG TAGGT GGTCA TCACT ACTAA TAAAT AATAC TACTT CTTTA TTAAC AACCA CCAAT AATAT TATAG TAGGC GGCAT CATAG TAGCG GCGCA GCACA ACAGA AGACA ACAGA AGATA ATAAA AAAAA AAATT ATTAC TACAG CAGAG GAGTA GTACA ACACA ACAAC AACAT CATCC TCCAT CATGA TGAAA AAACG ACGCA GCATT ATTAG TAGCA GCACC ACCAC CACCA CCATT ATTAC TACCA CCACC ACCAC CACCA CCATC ATCAC CACCA CCATT ATTAC TACCA CCACA ACAGG AGGTA GTAAC AACGG CGGTG GTGCG GCGGG GGGCT GCTGA TGACG ACGCG GCGTA GTACA ACAGG AGGAA GAAAC AACAC CACAG CAGAA GAAAA AAAAA AAAGC AGCCC CCCGC CGCAC CACCT CCTGA TGACA ACAGT AGTGC TGCGG CGGGC GGCTT CTTTT TTTTT TTTTT TTTTC TTCGA CGACC ACCAA CAAAG AAGGT GGTAA TAACG ACGAG GAGGT GGTAA TAACA ACAAC AACCA CCATG ATGCG GCGAG GAGTG GTGTT GTTGA TGAAG AAGTT GTTCG TCGGC GGCGG CGGTA GTACA ACATC ATCAG CAGTG GTGGC GGCAA CAAAT AATGC TGCAG CAGAA GAACG ACGTT GTTTT TTTCT TCTGC TGCGT CGTGT TGTTG TTGCC GCCGA CGATA ATATT ATTCT TCTGG TGGAA GAAAG AAGCA GCAAT AATGC TGCCA CCAGG AGGCA GCAGG AGGGG GGGCA GCAGG AGGTG GTGGC GGCCA CCACC ACCGT CGTCC TCCTC CTCTC CTCTG CTGCC GCCCC CCCCG CCGCC GCCAA CAAAA AAATC ATCAC CACCA CCAAC AACCA CCACC ACCTG CTGGT GGTGG TGGCG GCGAT GATGA TGATT ATTGA TGAAA AAAAA AAAAC AACCA CCATT ATTAG TAGCG GCGGC GGCCA CCAGG AGGAT GATGC TGCTT CTTTA TTACC ACCCA CCAAT AATAT TATCA TCAGC AGCGA CGATG ATGCC GCCGA CGAAC AACGT CGTAT TATTT TTTTT TTTGC TGCCG CCGAA GAACT ACTTT TTTTG TTGAC GACGG CGGGA GGACT ACTCG TCGCC GCCGC CGCCG CCGCC GCCCA CCAGC AGCCG CCGGG GGGGT GGTTC TTCCC CCCGC CGCTG CTGGC GGCGC CGCAA CAATT ATTGA TGAAA AAAAC AACTT CTTTC TTCGT CGTCG TCGAT GATCA TCAGG AGGAA GAATT ATTTG TTGCC GCCCA CCAAA AAATA ATAAA AAAAC AACAT CATGT TGTCC TCCTG CTGCA GCATG ATGGC GGCAT CATTA TTAGT AGTTT TTTGT TGTTG TTGGG GGGGC GGCAG CAGTG GTGCC GCCCG CCGGA GGATA ATAGC AGCAT CATCA TCAAC AACGC CGCTG CTGCG GCGCT GCTGA TGATT ATTTG TTGCC GCCGT CGTGG TGGCG GCGAG GAGAA GAAAA AAATG ATGTC GTCGA CGATC ATCGC CGCCA CCATT ATTAT TATGG TGGCC GCCGG CGGCG GCGTA GTATT ATTAG TAGAA GAAGC AGCGC CGCGC CGCGG CGGTC GTCAC CACAA CAACG ACGTT GTTAC TACTG CTGTT GTTAT TATCG TCGAT GATCC TCCGG CGGTC GTCGA CGAAA AAAAA AAACT ACTGC TGCTG CTGGC GGCAG CAGTG GTGGG GGGGC GGCAT CATTA TTACC ACCTC CTCGA CGAAT AATCT TCTAC TACCG CCGTC GTCGA CGATA ATATT ATTGC TGCTG CTGAG GAGTC GTCCA CCACC ACCCG CCGCC GCCGT CGTAT TATTG TTGCG GCGGC GGCAA CAAGC AGCCG CCGCA GCATT ATTCC TCCGG CGGCT GCTGA TGATC ATCAC CACAT CATGG TGGTG GTGCT GCTGA TGATG ATGGC,\n",
       " EmptyLabel )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we save the `itos` list from the dataloader as a numpy array. This is extremely important. When we transfer the pretrained weights from the language model to the classification model, we need to ensure the mapping from k-mers to integer ids is the same. Otherwise the embedding will be completely scrambled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path/'coli_vocab.npy', data.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model\n",
    "\n",
    "The configuration of the language model is very similar to the classification model. This is because we need the sizes of the embedding and LSTM layers in the language model to match those we want in the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=0, qrnn=False, output_p=0.25, \n",
    "                          hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15, tie_weights=True, out_bias=True)\n",
    "drop_mult = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_model_LM(data, drop_mult, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(1025, 400, padding_idx=0)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(1025, 400, padding_idx=0)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=1025, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained using the same learning rate/momentum scheduling described in the previous notebook.\n",
    "\n",
    "#### A note on language model performance\n",
    "\n",
    "If you decide to play around with different genomes, different k-mer sizes or strides, there are some important things to know about comparing performance between models. We measure performance via cross entropy loss and accuracy. These values are strongly influenced by the stride of the k-mers.\n",
    "\n",
    "Consider our stride 2 case. Any k-mer XXABC will be followed by a k-mer of the form ABCXX. The model quickly learns this mapping and places equal probability over all k-mers of the ABCXX form. For a stride of 2 (XX), this comes out to 16 (4^2) possible k-mers. I consider this point the baseline \"random guessing\" model that has only learned the most basic, obvious mapping encoded in the data. I think performance of these models should be measured relative to this baseline.\n",
    "\n",
    "We can relate the number of possible \"informed random guesses\" to the expected perplexity/cross entropy of the model. If we assume that each k-mer is equally distributed in the dataset and each of the 16 possible ABCXX k-mers is given equal proability by the model, we would expect the model's perplexity to be 16 and the cross entropy to be ln(16)=2.77.\n",
    "\n",
    "If you look at the validation loss of the model printed below, you can see it quickly trains down to a loss of around 2.7, then struggles to get lower. The model trains to a final validation loss of 2.63. This is to say the language model below is only slightly better than \"informed random\". However as we will see, this is more than enough to see a significant improvement in classification performance.\n",
    "\n",
    "Understanding the relationship between stride and the \"informed random\" baseline is important for comparing models that use different stride values. If a model has a stride of 1, we expect an \"informed random\" mapping of XABCD --> ABCDX. This would give an expected perplexity of 4 and a cross entropy of ln(4) = 1.38. This means that a stride 1 model with a loss of 1.38 is performing comprably to a stride 2 model with a loss of 2.77.\n",
    "\n",
    "Similarly for stride 3 models, we expect an \"informed random\" perplexity of 64 and a cross entropy of 4.15. Don't be fooled by the stride effect on apparent language model performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 5.25E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 06:15 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>6.370670</th>\n",
       "    <th>5.912199</th>\n",
       "    <th>0.012763</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>4.994476</th>\n",
       "    <th>3.697406</th>\n",
       "    <th>0.075818</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.442630</th>\n",
       "    <th>2.773268</th>\n",
       "    <th>0.110109</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>2.938919</th>\n",
       "    <th>2.743901</th>\n",
       "    <th>0.114065</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>2.801513</th>\n",
       "    <th>2.727318</th>\n",
       "    <th>0.116647</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>2.757425</th>\n",
       "    <th>2.717677</th>\n",
       "    <th>0.119910</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>2.734499</th>\n",
       "    <th>2.686177</th>\n",
       "    <th>0.131400</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>2.701397</th>\n",
       "    <th>2.667752</th>\n",
       "    <th>0.135593</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>2.682082</th>\n",
       "    <th>2.660521</th>\n",
       "    <th>0.138789</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>2.675452</th>\n",
       "    <th>2.659334</th>\n",
       "    <th>0.139528</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 06:15 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>2.672501</th>\n",
       "    <th>2.660848</th>\n",
       "    <th>0.138806</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>2.828697</th>\n",
       "    <th>2.696011</th>\n",
       "    <th>0.130670</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>2.717998</th>\n",
       "    <th>2.660706</th>\n",
       "    <th>0.138572</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>2.679060</th>\n",
       "    <th>2.647541</th>\n",
       "    <th>0.142135</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>2.662118</th>\n",
       "    <th>2.642828</th>\n",
       "    <th>0.143249</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>2.650700</th>\n",
       "    <th>2.637081</th>\n",
       "    <th>0.145248</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>2.639304</th>\n",
       "    <th>2.633259</th>\n",
       "    <th>0.145073</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>2.626284</th>\n",
       "    <th>2.630747</th>\n",
       "    <th>0.146867</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>2.615709</th>\n",
       "    <th>2.628789</th>\n",
       "    <th>0.147054</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>2.608753</th>\n",
       "    <th>2.629214</th>\n",
       "    <th>0.147117</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 5e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 06:15 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>2.604931</th>\n",
       "    <th>2.628959</th>\n",
       "    <th>0.147313</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>2.607383</th>\n",
       "    <th>2.630346</th>\n",
       "    <th>0.146666</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>2.605536</th>\n",
       "    <th>2.630502</th>\n",
       "    <th>0.145427</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>2.601106</th>\n",
       "    <th>2.628724</th>\n",
       "    <th>0.146579</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>2.593615</th>\n",
       "    <th>2.630724</th>\n",
       "    <th>0.146324</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>2.583986</th>\n",
       "    <th>2.633168</th>\n",
       "    <th>0.145561</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>2.572123</th>\n",
       "    <th>2.631822</th>\n",
       "    <th>0.146191</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>2.562679</th>\n",
       "    <th>2.633929</th>\n",
       "    <th>0.145682</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>2.553378</th>\n",
       "    <th>2.635001</th>\n",
       "    <th>0.145694</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>2.550403</th>\n",
       "    <th>2.635109</th>\n",
       "    <th>0.145728</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the model and transfer over to classification.\n",
    "\n",
    "#### A note on fine tuning\n",
    "\n",
    "If we were to follow ULMFiT proper, the next step would be to fine tune the language model on the promoter corpus. In practice I have found that trying to fine tune the language model in this way quickly overfits, leading to worse classification performance. I believe this is due to the total text length of the promoter corpus. I will revisit this later with a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('coli_only_LM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('coli_only_LM_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Now we run the classification procedure exactly the same as the last notebook. The only difference is now we initialize the classification model with the encoder (embedding + LSTMs) of the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(path/'e_coli_promoters_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Locus</th>\n",
       "      <th>Location</th>\n",
       "      <th>Sample Location</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Promoter</th>\n",
       "      <th>Independent</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['mokC']</td>\n",
       "      <td>['b0018']</td>\n",
       "      <td>[16750:16960](-)</td>\n",
       "      <td>[16910:17060](-)</td>\n",
       "      <td>reverse</td>\n",
       "      <td>TAGCGGCGGGTGCTTGAGGCTGTCTGTCTCAGGCATTAGCTGAACG...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['insB-1']</td>\n",
       "      <td>['b0021']</td>\n",
       "      <td>[19810:20314](-)</td>\n",
       "      <td>[20264:20414](-)</td>\n",
       "      <td>reverse</td>\n",
       "      <td>GCTCTCACTGCCGTAAAACATGGCAACTGCAGTTCACTTACACCGC...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['insA-1']</td>\n",
       "      <td>['b0022']</td>\n",
       "      <td>[20232:20508](-)</td>\n",
       "      <td>[20458:20608](-)</td>\n",
       "      <td>reverse</td>\n",
       "      <td>GACTCCCCCACAAAGAATATGGATATTGTGATACACATTGAGGTAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['rpsT']</td>\n",
       "      <td>['b0023']</td>\n",
       "      <td>[20814:21078](-)</td>\n",
       "      <td>[21028:21178](-)</td>\n",
       "      <td>reverse</td>\n",
       "      <td>ACGGCGCTTATTTGCACAAATCCATTGACAAAAGAAGGCTAAAAGG...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['fkpB']</td>\n",
       "      <td>['b0028']</td>\n",
       "      <td>[25825:26275](+)</td>\n",
       "      <td>[25725:25875](+)</td>\n",
       "      <td>forward</td>\n",
       "      <td>ACGCATCTTATCCGGCCTACAGATTGCTGCGAAATCGTAGGCCGGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gene      Locus          Location   Sample Location Orientation  \\\n",
       "0    ['mokC']  ['b0018']  [16750:16960](-)  [16910:17060](-)     reverse   \n",
       "1  ['insB-1']  ['b0021']  [19810:20314](-)  [20264:20414](-)     reverse   \n",
       "2  ['insA-1']  ['b0022']  [20232:20508](-)  [20458:20608](-)     reverse   \n",
       "3    ['rpsT']  ['b0023']  [20814:21078](-)  [21028:21178](-)     reverse   \n",
       "4    ['fkpB']  ['b0028']  [25825:26275](+)  [25725:25875](+)     forward   \n",
       "\n",
       "                                            Sequence  Promoter  Independent  \\\n",
       "0  TAGCGGCGGGTGCTTGAGGCTGTCTGTCTCAGGCATTAGCTGAACG...         1        False   \n",
       "1  GCTCTCACTGCCGTAAAACATGGCAACTGCAGTTCACTTACACCGC...         1        False   \n",
       "2  GACTCCCCCACAAAGAATATGGATATTGTGATACACATTGAGGTAG...         1        False   \n",
       "3  ACGGCGCTTATTTGCACAAATCCATTGACAAAAGAAGGCTAAAAGG...         1        False   \n",
       "4  ACGCATCTTATCCGGCCTACAGATTGCTGCGAAATCGTAGGCCGGA...         1        False   \n",
       "\n",
       "     set  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = classification_df[classification_df.set == 'train']\n",
    "valid_df = classification_df[classification_df.set == 'valid']\n",
    "test_df = classification_df[classification_df.set == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Vocabulary\n",
    "\n",
    "Here we create a dataloader for tokenizing and numericalizing genomic sequences, same as before. However, we now pass in the vocabulary of the language model as a parameter for the classification dataloader. This ensures the mapping from k-mer to integer to embedding stays the same.\n",
    "\n",
    "## If you do not do this, everything will fail\n",
    "\n",
    "The exact order of the numericalization is based on the order in which tokens are processed. Different datasets or different shuffles of the same dataset __will__ have different vocabulary orders. If you try to transfer over a model with an incorrect vocabulary, it will basically refuse to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = np.load(path/'coli_vocab.npy')\n",
    "model_vocab = GenomicVocab(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(GenomicTokenizer, n_cpus=1, pre_rules=[], post_rules=[], special_cases=['xxpad'])\n",
    "data_clas = GenomicTextClasDataBunch.from_df(path, train_df, valid_df, tokenizer=tok, vocab=model_vocab,\n",
    "                                            text_cols='Sequence', label_cols='Promoter', bs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the same classification model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=0, qrnn=False, output_p=0.4, \n",
    "                       hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)\n",
    "drop_mult = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_model_clas(data_clas, drop_mult, clas_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1025, 400, padding_idx=0)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1025, 400, padding_idx=0)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.24)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the encoder of the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load_encoder('coli_only_LM_enc')\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 3.63E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure\n",
    "\n",
    "Here we follow the ULMFiT procedure of training with gradual unfreezing. We first train only the new classification layer of the model, then gradually the lower LSTM and embedding layers.\n",
    "\n",
    "You can see here that after a single epoch of training only the linear section (keeping the embedding/LSTMs as is from the language model) the classification model has achieved the same accuracy as the final model without pretraining.\n",
    "\n",
    "When the entire model is being trained, we use discriminitive learning rates to train the lower layers of the model at a lower learning rate than the higher layers. This allows us to apply larger parameter updates to the new linear classification head, and smaller updates to the well-trained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:10 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.471390</th>\n",
       "    <th>0.502219</th>\n",
       "    <th>0.817333</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.417666</th>\n",
       "    <th>0.374258</th>\n",
       "    <th>0.850667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.389217</th>\n",
       "    <th>0.338804</th>\n",
       "    <th>0.862667</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:11 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.336214</th>\n",
       "    <th>0.272439</th>\n",
       "    <th>0.898667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.297485</th>\n",
       "    <th>0.229910</th>\n",
       "    <th>0.910667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.256147</th>\n",
       "    <th>0.245506</th>\n",
       "    <th>0.902667</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(3, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:19 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.193945</th>\n",
       "    <th>0.278206</th>\n",
       "    <th>0.886667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.174481</th>\n",
       "    <th>0.264147</th>\n",
       "    <th>0.898667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.151469</th>\n",
       "    <th>0.220725</th>\n",
       "    <th>0.921333</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(3, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:44 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.110926</th>\n",
       "    <th>0.222714</th>\n",
       "    <th>0.922667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.111169</th>\n",
       "    <th>0.226468</th>\n",
       "    <th>0.921333</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.103627</th>\n",
       "    <th>0.238019</th>\n",
       "    <th>0.921333</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.100020</th>\n",
       "    <th>0.240490</th>\n",
       "    <th>0.922667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.095884</th>\n",
       "    <th>0.240475</th>\n",
       "    <th>0.922667</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:45 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.082540</th>\n",
       "    <th>0.240896</th>\n",
       "    <th>0.922667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.087917</th>\n",
       "    <th>0.244476</th>\n",
       "    <th>0.922667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.084610</th>\n",
       "    <th>0.238354</th>\n",
       "    <th>0.921333</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.085201</th>\n",
       "    <th>0.244506</th>\n",
       "    <th>0.922667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.085244</th>\n",
       "    <th>0.243561</th>\n",
       "    <th>0.920000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('coli_coli_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = GenomicTextClasDataBunch.from_df(path, train_df, test_df, tokenizer=tok, vocab=model_vocab,\n",
    "                                            text_cols='Sequence', label_cols='Promoter', bs=300)\n",
    "learn.data = data_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9192771084337349\n",
      "False Positives: 0.027710843373493974\n",
      "False Negatives: 0.05301204819277108\n",
      "Recall: 0.8939759036144578\n",
      "Precision: 0.9416243654822335\n",
      "MCC: 0.8396298856628701\n"
     ]
    }
   ],
   "source": [
    "get_scores(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the naive model, accuracy has increased from 83.4% to 91.9%, precision has increased from 0.84 to 0.94, recall has increased from 0.81 to 0.89, and the correlation coefficient has increased from 0.67 to 0.83.\n",
    "\n",
    "The model is also much more stable during training and gives more reproducible results. Unsupervised pretraining helps a lot.\n",
    "\n",
    "In fact, the best way to improve the model from this point is not to train more on the promoter dataset, but to create a better genomic language model from more genomic data. This is detailed in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
