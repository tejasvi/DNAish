{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Genome Data Processing\n",
    "\n",
    "This notebook creates the dataset needed to train a classification model on short promoter sequences from the human genome\n",
    "\n",
    "#### Human Promoter Classification Short Sequences\n",
    "This dataset will be made with sequences used in the paper [Recognition of Prokaryotic and Eukaryotic Promoters using Convolutional Deep Learning Neural Networks](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0171410). This dataset consists of small (250 bp) sequences centered approximately -200/50 around TSS sites. The data also contains negative examples of the same length. The data files `human_non_tata.fa` and `human_nonprom_big.fa` are downloaded from [this repo](https://github.com/solovictor/CNNPromoterData). The paper specifically uses two different models for classifying `tata` containing promoters and `non-tata` promoters. However the dataset for the `tata` promoters is not in the repo, and therefore will not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from Bio import Seq\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import FeatureLocation, CompoundLocation\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../..\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('F:/genome/human/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Sequence Classification Data\n",
    "\n",
    "Similar to the paper, 15% of the sequences will be used for testing. Of the remaining, 90% of the sequences will be used for training and 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname1 = 'human_non_tata.fa'\n",
    "fname2 = 'human_nonprom_big.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta1 = SeqIO.parse(path/fname1, 'fasta')\n",
    "seqs1 = [i.seq.__str__() for i in fasta1 if set(i.seq.__str__()) == set('ATGC')]\n",
    "seq1_df = pd.DataFrame(seqs1, columns=['Sequence'])\n",
    "seq1_df['Promoter'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta2 = SeqIO.parse(path/fname2, 'fasta')\n",
    "seqs2 = [i.seq.__str__() for i in fasta2 if set(i.seq.__str__()) == set('ATGC')]\n",
    "seq2_df = pd.DataFrame(seqs2, columns=['Sequence'])\n",
    "seq2_df['Promoter'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19809, 2), (27703, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1_df.shape, seq2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1_df.drop_duplicates(inplace=True)\n",
    "seq2_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19787, 2), (27038, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1_df.shape, seq2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(df):\n",
    "    \n",
    "    train_size = int(len(df)*0.85*.9)\n",
    "    valid_size = int(len(df)*0.85) - train_size\n",
    "    \n",
    "    train_df = df.sample(train_size)\n",
    "    test_val = df.drop(train_df.index)\n",
    "    valid_df = test_val.sample(valid_size)\n",
    "    test_df = test_val.drop(valid_df.index)\n",
    "    train_df['set'] = 'train'\n",
    "    valid_df['set'] = 'valid'\n",
    "    test_df['set'] = 'test'\n",
    "    \n",
    "    return (train_df, valid_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, v1, test1 = partition_data(seq1_df)\n",
    "t2, v2, test2 = partition_data(seq2_df)\n",
    "data_df = pd.concat([t1,t2,v1,v2,test1,test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35821, 3), (3979, 3), (7025, 3), (46825, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df.set == 'train'].shape, data_df[data_df.set == 'valid'].shape, data_df[data_df.set == 'test'].shape, data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(path/'human_promoters_short.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
